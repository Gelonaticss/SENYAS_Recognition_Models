{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label        x0        x1        x2        x3        x4        x5        x6  \\\n",
      "0     A  0.554168  0.684206  0.389772  0.606572  0.283965  0.465491  0.252456   \n",
      "1     A  0.556177  0.689428  0.392216  0.611702  0.284852  0.468364  0.252625   \n",
      "2     A  0.556366  0.693857  0.390297  0.615060  0.284599  0.470269  0.252736   \n",
      "3     A  0.556366  0.693857  0.390297  0.615060  0.284599  0.470269  0.252736   \n",
      "4     A  0.554369  0.692465  0.389453  0.615414  0.283311  0.471962  0.252191   \n",
      "\n",
      "         x7        x8  ...       y11       y12       y13       y14       y15  \\\n",
      "0  0.344239  0.237564  ...  0.515263  0.523408  0.645037  0.393724  0.608905   \n",
      "1  0.346933  0.238654  ...  0.519778  0.521089  0.648092  0.395297  0.612985   \n",
      "2  0.347473  0.236668  ...  0.521397  0.525343  0.651389  0.399802  0.615364   \n",
      "3  0.347473  0.236668  ...  0.521397  0.525343  0.651389  0.399802  0.615364   \n",
      "4  0.350223  0.237265  ...  0.516037  0.530796  0.649512  0.401028  0.612253   \n",
      "\n",
      "        y16       y17       y18       y19       y20  \n",
      "0  0.328622  0.592930  0.422422  0.589715  0.496160  \n",
      "1  0.329441  0.597734  0.420963  0.593342  0.494881  \n",
      "2  0.331018  0.596923  0.423533  0.592556  0.498355  \n",
      "3  0.331018  0.596923  0.423533  0.592556  0.498355  \n",
      "4  0.332488  0.595261  0.425078  0.590999  0.500063  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"landmarks_dataset.csv\")\n",
    "print(df.head())  # Shows the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data count per letter:\n",
      "Label\n",
      "A    600\n",
      "B    400\n",
      "C    345\n",
      "D    400\n",
      "E    400\n",
      "F    400\n",
      "G    375\n",
      "H    400\n",
      "I    400\n",
      "J    391\n",
      "K    400\n",
      "L    400\n",
      "M    400\n",
      "N    395\n",
      "O    400\n",
      "P    339\n",
      "Q    328\n",
      "R    363\n",
      "S    400\n",
      "T    400\n",
      "U    380\n",
      "V    400\n",
      "W    398\n",
      "X    400\n",
      "Y    400\n",
      "Z    290\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)  # Show all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "\n",
    "# Load the extracted dataset\n",
    "csv_file = \"landmarks_dataset.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Count the number of data points per letter\n",
    "letter_counts = df.iloc[:, 0].value_counts().sort_index()  # Sort alphabetically\n",
    "\n",
    "# Display counts per letter\n",
    "print(\"\\nData count per letter:\")\n",
    "print(letter_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data keys: Index(['Label', 'x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
      "       'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19',\n",
      "       'x20', 'y0', 'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9',\n",
      "       'y10', 'y11', 'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y18', 'y19',\n",
      "       'y20'],\n",
      "      dtype='object')\n",
      "Unexpected pickle format: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "pickle_file = \"landmarks_dataset.pkl\"\n",
    "\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Print the keys and first few items\n",
    "print(\"Data keys:\", data.keys())\n",
    "\n",
    "# Check the first few items\n",
    "if isinstance(data, dict):\n",
    "    print(\"Sample labels:\", data.get(\"labels\", [])[:5])\n",
    "    print(\"Sample landmarks:\", data.get(\"landmarks\", [])[:5])\n",
    "else:\n",
    "    print(\"Unexpected pickle format:\", type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully reformatted and saved to landmarks_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from pickle\n",
    "pickle_file = \"landmarks_dataset.pkl\"\n",
    "df = pd.read_pickle(pickle_file)  # Load as DataFrame\n",
    "\n",
    "# Convert DataFrame to dictionary format\n",
    "data = {\n",
    "    \"labels\": df.iloc[:, 0].tolist(),  # First column is labels\n",
    "    \"landmarks\": df.iloc[:, 1:].values.tolist()  # Remaining columns are landmarks\n",
    "}\n",
    "\n",
    "# Save correctly formatted pickle file\n",
    "with open(pickle_file, \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(f\"Dataset successfully reformatted and saved to {pickle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['labels', 'landmarks'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"landmarks_dataset.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))  # Check if it's a dict, list, or DataFrame\n",
    "print(data.keys())  # Show available keys in the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    600\n",
      "S    400\n",
      "V    400\n",
      "O    400\n",
      "B    400\n",
      "M    400\n",
      "L    400\n",
      "K    400\n",
      "I    400\n",
      "H    400\n",
      "X    400\n",
      "F    400\n",
      "E    400\n",
      "D    400\n",
      "Y    400\n",
      "T    400\n",
      "W    398\n",
      "N    395\n",
      "J    391\n",
      "U    380\n",
      "G    375\n",
      "R    363\n",
      "C    345\n",
      "P    339\n",
      "Q    328\n",
      "Z    290\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"landmarks_dataset.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Access labels correctly\n",
    "labels = data[\"labels\"]  # Extract labels\n",
    "\n",
    "# Count occurrences of each letter\n",
    "print(pd.Series(labels).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
